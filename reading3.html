Matt Webb’s distinction between “cyborgs” and “rooms” helped me put words to a tension I’ve felt about current AI products. The cyborg vision, wearables, AI glasses, smart rings, feels like technology collapsing inward, turning the human body into the interface. Webb’s examples (AirPods transparency mode, Meta AI glasses) made me realize how normalized this already is: when information is fed directly into our perception, it starts to feel less like “using a tool” and more like thinking itself.

What I found more compelling, though, was Webb’s preference for room-scale computing. The idea of computers as environments you enter and leave feels healthier, both cognitively and socially. Instead of constant augmentation, rooms allow for shared, multi-actor experiences, something personal devices struggle to support. I liked the comparison to somaforming vs. terraforming: adapting ourselves to technology versus adapting technology to us. It reframes the debate in a gentler, more ethical way.

This made me think about how much current AI design prioritizes individual optimization over collective interaction. Smart glasses and personal AI assistants are powerful, but isolating. Room-scale systems, smart spaces, ambient computing, robotics, suggest a future where technology supports collaboration and presence rather than permanent attachment. Webb’s question at the end stuck with me: if everyone is building cyborg tech, what are we missing by not designing the rooms we actually live in?